{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FilterVariables.ipyn\n",
    "\n",
    "#### A code to plot variability parameters for all sources in a given dataset and to select the candidate variables using input sigma thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all the dependencies and generic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.orm import relationship\n",
    "import tkp.db\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "query_loglevel = logging.WARNING  # Set to INFO to see queries, otherwise WARNING\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dblogin import * # This file contains all the variables required to connect to the database\n",
    "from databaseTools import dbtools\n",
    "from tools import tools\n",
    "# from plotting import plot_varib_params as pltvp\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['legend.loc'] = 'best'\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input database, dataset and thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database = 'AR_R4'\n",
    "sigma1 = 2 # Threshold on the reduced weighted chi^2\n",
    "sigma2 = 2 # Threshold on the variability parameter\n",
    "websiteURL = 'http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "\n",
    "# this option is necessary for outputting pandas dataframes (strings are also accepted)\n",
    "tables = ['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "websiteURL = 'http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "latexURL = '\\url{http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "latexHREF = '\\href{http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "query_loglevel = logging.WARNING  # Set to INFO to see queries, otherwise WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option1: Connect to the database and run the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tkp.db.database:Not configuring pre-configured database\n",
      "INFO:tkp.db.database:connecting to database...\n",
      "ERROR:sqlalchemy.pool.NullPool:Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kmeulen/virtualenv/local/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 705, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/home/kmeulen/virtualenv/local/lib/python2.7/site-packages/sqlalchemy/pool.py\", line 876, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/kmeulen/virtualenv/local/lib/python2.7/site-packages/sqlalchemy/engine/default.py\", line 457, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "OperationalError: SSL connection has been closed unexpectedly\n",
      "\n",
      "INFO:tkp.db.database:connected to: postgresql://kmeulen@vlo.science.uva.nl:5432/KmeulenTrap4P23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected!\n"
     ]
    }
   ],
   "source": [
    "session = dbtools.access(engine,host,port,user,password,database)\n",
    "VarParams = dbtools.GetVarParams(session,dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option1: Set up data for plotting\n",
    "\n",
    "Obtain data to plot the variability paramters against the reduced weighted chi^2. All sources with fewer than 1 datapoints are excluded. Columns are [runcat_id, eta_nu, V_nu, lightcurve_max, lightcurve_median, nu, number of datapoints, new source id]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = [[VarParams[i].Runningcatalog.id, VarParams[i].Varmetric.eta_int, VarParams[i].Varmetric.v_int, VarParams[i].Varmetric.lightcurve_max, VarParams[i].Varmetric.lightcurve_median, (VarParams[i].Varmetric.band.freq_central/1e6), VarParams[i].Runningcatalog.datapoints, VarParams[i].Varmetric.newsource] for i in range(len(VarParams))]\n",
    "plotdata = pd.DataFrame(data=plotdata,columns=['runcat','eta','V','maxFlx','avgFlx','freq','dpts','newSrc'])\n",
    "plotdata = plotdata.fillna('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option2: fetch data from database and return as pandas dataframe\n",
    "\n",
    "The following tables from the schema are allready employed:\n",
    "* Varmetric\n",
    "* Runningcatalog\n",
    "* Extractedsource\n",
    "* Newsource\n",
    "* Image\n",
    "\n",
    "for more info check the schema out or the dbtools.py script for the code behind GetPandaExtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 4\n",
    "PandasParams = dbtools.GetPandaExtracted(session,dataset_id,tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to view the columns of the frame and acces the head and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([           u'xtrsrc',           u'dataset',            u'runcat',\n",
      "              u'datapoints',              u'zone',             u'wm_ra',\n",
      "                 u'wm_decl', u'wm_uncertainty_ew', u'wm_uncertainty_ns',\n",
      "              u'avg_ra_err',      u'avg_decl_err',           u'avg_wra',\n",
      "               u'avg_wdecl',     u'avg_weight_ra',   u'avg_weight_decl',\n",
      "                       u'x',                 u'y',                 u'z',\n",
      "                u'inactive',           u'mon_src',  u'forcedfits_count',\n",
      "                    u'band',            u'skyrgn',             u'image',\n",
      "                     u'tau',            u'stokes',          u'tau_time',\n",
      "                u'freq_eff',           u'freq_bw',       u'taustart_ts',\n",
      "                 u'rb_smaj',           u'rb_smin',             u'rb_pa',\n",
      "                  u'deltax',            u'deltay',       u'fwhm_arcsec',\n",
      "             u'fov_degrees',            u'rms_qc',           u'rms_min',\n",
      "                 u'rms_max',  u'detection_thresh',   u'analysis_thresh',\n",
      "                     u'url',              u'node',             u'nodes',\n",
      "             u'fits_header',         u'fits_data'],\n",
      "      dtype='object')\n",
      "0.0660333225674\n",
      "0.0010654708285954574\n",
      "Series([], Name: rms_max, dtype: float64)\n",
      "0.000474010292427\n"
     ]
    }
   ],
   "source": [
    "print PandasParams.keys()\n",
    "print max(PandasParams['rms_max'])\n",
    "print np.mean(PandasParams['rms_qc'])\n",
    "# print PandasParams['rms_qc']\n",
    "s = set(PandasParams['rms_min'])\n",
    "# PandasParams.head().style\n",
    "\n",
    "# print PandasParams['rms_min'][PandasParams.query('image == 1')]\n",
    "ls = PandasParams[PandasParams.image ==11]\n",
    "print ls.rms_max\n",
    "print sorted(s)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of VarParams\n",
    "\n",
    "The VarParams array contains all the information for the unique running catalogue sources for the required dataset. Each running catalogue source has a row in this array.\n",
    "\n",
    "\n",
    "Runningcatalog table contains the parameters (see http://tkp.readthedocs.io/en/r3.0/devref/database/schema.html#runningcatalog), but especially:\n",
    " * id\n",
    " * dataset_id\n",
    " * wm_ra (in degrees)\n",
    " * wm_decl (in degrees)\n",
    " * avg_ra_err (in degrees)\n",
    " * avg_decl_err (in degrees)\n",
    "\n",
    "\n",
    "Varmetric table contains (see http://tkp.readthedocs.io/en/r3.0/devref/database/schema.html#varmetric), but especially:\n",
    " * varmetric (id from varmetric)\n",
    " * Varmetric.runcat (link to Runningcatalog table)\n",
    " * v_int (the variability parameter for the last datapoint in the lightcurve)\n",
    " * eta_int (the reduced weighted chi^2 for the last datapoint in the lightcurve)\n",
    " * band (a link back to Frequencyband table)\n",
    " * newsource  (a link back to newsource table)\n",
    " * sigma_rms_max (SNR max for new sources)\n",
    " * sigma_rms_min (SNR min for new sources)\n",
    " * lightcurve_max (maximum flux in the lightcurve)\n",
    " * lightcurve_avg (mean flux in the lightcurve)\n",
    " * lightcurve_median (median flux in the lightcurve)\n",
    "\n",
    "#### Example queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print VarParams[1].Varmetric.runcat.dataset_id\n",
    "#print VarParams[1].Runningcatalog.id\n",
    "#print [VarParams[i].Runningcatalog.id for i in range(len(VarParams))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian fitting to population variability parameters\n",
    "\n",
    "Obtaining the Gaussian fit parameters in log space for the reduced weighted Chi^2 and the variability parameter. The first parameters assume a median clipped distribution (all values 4 sigma away from median are clipped) whereas the other simply fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = plotdata.loc[(plotdata['eta'] > 0) & (plotdata['V'] > 0) & (plotdata['dpts']>1) & (plotdata['newSrc']=='N')]\n",
    "paramx, paramx2 = tools.SigmaFit(np.log10(plotdata['eta']))\n",
    "paramy, paramy2 = tools.SigmaFit(np.log10(plotdata['V']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sigma1 == 0:\n",
    "    sigcutx = 0\n",
    "else:\n",
    "    sigcutx = paramx[1]*sigma1+paramx[0]\n",
    "\n",
    "if sigma2 == 0:\n",
    "    sigcuty = 0\n",
    "else:\n",
    "    sigcuty = paramy[1]*sigma2+paramy[0]\n",
    "\n",
    "print('Gaussian Fit eta: '+str(round(10.**paramx[0],2))+'(+'+str(round((10.**(paramx[0]+paramx[1])-10.**paramx[0]),2))+' '+str(round((10.**(paramx[0]-paramx[1])-10.**paramx[0]),2))+')')\n",
    "print('Gaussian Fit V: '+str(round(10.**paramy[0],2))+'(+'+str(round((10.**(paramy[0]+paramy[1])-10.**paramy[0]),2))+' '+str(round((10.**(paramy[0]-paramy[1])-10.**paramy[0]),2))+')')\n",
    "print 'Eta_nu threshold='+str(10.**sigcutx)+', V_nu threshold='+str(10.**sigcuty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Find the unique frequencies for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = plotdata.freq.unique()\n",
    "print frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a colourmap for each of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pltvp.make_cmap(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating eta V plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullfmt   = NullFormatter()         # no labels\n",
    "fontP = FontProperties()\n",
    "fontP.set_size('large')\n",
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "bottom_h = left_h = left+width+0.02\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histx = [left, bottom_h, width, 0.2]\n",
    "rect_histy = [left_h, bottom, 0.2, height]\n",
    "fig = plt.figure(1,figsize=(12,12))\n",
    "axScatter = fig.add_subplot(223, position=rect_scatter)\n",
    "plt.xlabel(r'$\\eta_{\\nu}$', fontsize=28)\n",
    "plt.ylabel(r'$V_{\\nu}$', fontsize=28)\n",
    "axHistx=fig.add_subplot(221, position=rect_histx)\n",
    "axHisty=fig.add_subplot(224, position=rect_histy)\n",
    "axHistx.xaxis.set_major_formatter(nullfmt)\n",
    "axHisty.yaxis.set_major_formatter(nullfmt)\n",
    "axHistx.axes.yaxis.set_ticklabels([])\n",
    "axHisty.axes.xaxis.set_ticklabels([])\n",
    "\n",
    "for i in range(len(frequencies)):\n",
    "    plotdataTMP=plotdata.loc[(plotdata['freq']==frequencies[i])]\n",
    "    xdata_var=np.log10(plotdataTMP['eta'])\n",
    "    ydata_var=np.log10(plotdataTMP['V'])\n",
    "    axScatter.scatter(xdata_var, ydata_var,color=col[i], s=10., zorder=5)\n",
    "\n",
    "x = np.log10(plotdata['eta'])\n",
    "y = np.log10(plotdata['V'])\n",
    "\n",
    "axHistx.hist(x, bins=pltvp.make_bins(x), normed=1, histtype='stepfilled', color='b')\n",
    "axHisty.hist(y, bins=pltvp.make_bins(y), normed=1, histtype='stepfilled', orientation='horizontal', color='b')\n",
    "\n",
    "freq_labels=[int(f) for f in frequencies]\n",
    "axScatter.legend(freq_labels,loc=4, prop=fontP)\n",
    "xmin=int(min(x)-1.1)\n",
    "xmax=int(max(x)+1.1)\n",
    "ymin=int(min(y)-1.1)\n",
    "ymax=int(max(y)+1.1)\n",
    "xvals=range(xmin,xmax)\n",
    "xtxts=[r'$10^{'+str(a)+'}$' for a in xvals]\n",
    "yvals=range(ymin,ymax)\n",
    "ytxts=[r'$10^{'+str(a)+'}$' for a in yvals]\n",
    "axScatter.set_xlim([xmin,xmax])\n",
    "axScatter.set_ylim([ymin,ymax])\n",
    "axScatter.set_xticks(xvals)\n",
    "axScatter.set_xticklabels(xtxts, fontsize=20)\n",
    "axScatter.set_yticks(yvals)\n",
    "axScatter.set_yticklabels(ytxts, fontsize=20)\n",
    "axHistx.set_xlim( axScatter.get_xlim())\n",
    "axHisty.set_ylim( axScatter.get_ylim())\n",
    "\n",
    "if sigcutx != 0 or sigcuty != 0:\n",
    "    axHistx.axvline(x=sigcutx, linewidth=2, color='k', linestyle='--')\n",
    "    axHisty.axhline(y=sigcuty, linewidth=2, color='k', linestyle='--')\n",
    "    axScatter.axhline(y=sigcuty, linewidth=2, color='k', linestyle='--')\n",
    "    axScatter.axvline(x=sigcutx, linewidth=2, color='k', linestyle='--')\n",
    "\n",
    "range_x,fitx = pltvp.gaussian_fit(x,paramx)\n",
    "axHistx.plot(range_x,fitx, 'k:', linewidth=2)\n",
    "range_y,fity = pltvp.gaussian_fit(y,paramy)\n",
    "axHisty.plot(fity,range_y, 'k:', linewidth=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black dashed lines represent the sigma thresholds imposed on the data.\n",
    "Black dotted lines show the histogram fit used to calculate the sigma thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create diagnostic plots \n",
    "eta and V versus the average flux and ratio of max flux and average flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(12,12))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "fontP = FontProperties()\n",
    "fontP.set_size('large')\n",
    "fig.subplots_adjust(hspace = .001, wspace = 0.001)\n",
    "ax1.set_ylabel(r'$\\eta_\\nu$', fontsize=28)\n",
    "ax3.set_ylabel(r'$V_\\nu$', fontsize=28)\n",
    "ax3.set_xlabel('Max Flux (Jy)', fontsize=24)\n",
    "ax4.set_xlabel('Max Flux / Median Flux', fontsize=24)\n",
    "\n",
    "for i in range(len(frequencies)):\n",
    "    plotdataTMP=plotdata.loc[(plotdata['freq']==frequencies[i])]\n",
    "    xdata_ax3=plotdataTMP['maxFlx']\n",
    "    xdata_ax4=plotdataTMP['maxFlx']/plotdataTMP['avgFlx']\n",
    "    ydata_ax1=plotdataTMP['eta']\n",
    "    ydata_ax3=plotdataTMP['V']\n",
    "    ax1.scatter(xdata_ax3, ydata_ax1,color=col[i], s=10., zorder=5)\n",
    "    ax2.scatter(xdata_ax4, ydata_ax1,color=col[i], s=10., zorder=6)\n",
    "    ax3.scatter(xdata_ax3, ydata_ax3,color=col[i], s=10., zorder=7)\n",
    "    ax4.scatter(xdata_ax4, ydata_ax3,color=col[i], s=10., zorder=8)\n",
    "    ax4.legend(freq_labels, loc=4, prop=fontP)\n",
    "\n",
    "Xax3=plotdata['maxFlx']\n",
    "Xax4=plotdata['maxFlx']/plotdataTMP['avgFlx']\n",
    "Yax1=plotdata['eta']\n",
    "Yax3=plotdata['V']\n",
    "    \n",
    "if sigcutx != 0 or sigcuty != 0:\n",
    "    ax1.axhline(y=10.**sigcutx, linewidth=2, color='k', linestyle='--')\n",
    "    ax2.axhline(y=10.**sigcutx, linewidth=2, color='k', linestyle='--')\n",
    "    ax3.axhline(y=10.**sigcuty, linewidth=2, color='k', linestyle='--')\n",
    "    ax4.axhline(y=10.**sigcuty, linewidth=2, color='k', linestyle='--')\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_xscale('log')\n",
    "ax4.set_yscale('log')\n",
    "xmin_ax3=10.**(int(np.log10(min(Xax3))-1.1))\n",
    "xmax_ax3=10.**(int(np.log10(max(Xax3))+1.2))\n",
    "xmin_ax4=0.8\n",
    "xmax_ax4=int(max(xdata_ax4)+0.5)\n",
    "ymin_ax1=10.**(int(np.log10(min(Yax1))-1.1))\n",
    "ymax_ax1=10.**(int(np.log10(max(Yax1))+1.2))\n",
    "ymin_ax3=10.**(int(np.log10(min(Yax3))-1.1))\n",
    "ymax_ax3=10.**(int(np.log10(max(Yax3))+1.2))\n",
    "ax1.set_ylim(ymin_ax1,ymax_ax1)\n",
    "ax3.set_ylim(ymin_ax3,ymax_ax3)\n",
    "ax3.set_xlim(xmin_ax3,xmax_ax3)\n",
    "ax4.set_xlim(xmin_ax4,xmax_ax4)\n",
    "ax1.set_xlim( ax3.get_xlim() )\n",
    "ax4.set_ylim( ax3.get_ylim() )\n",
    "ax2.set_xlim( ax4.get_xlim() )\n",
    "ax2.set_ylim( ax1.get_ylim() )\n",
    "ax1.xaxis.set_major_formatter(nullfmt)\n",
    "ax4.yaxis.set_major_formatter(nullfmt)\n",
    "ax2.xaxis.set_major_formatter(nullfmt)\n",
    "ax2.yaxis.set_major_formatter(nullfmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the URL to the Banana webpage for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp=[x[0] for x in plotdata if x[1]>10.**sigcutx and x[2]>10.**sigcuty and x[7]==None and x[6]>1]\n",
    "tmp=plotdata.loc[(plotdata['eta']>=10.**sigcutx) & (plotdata['V']>=10.**sigcuty)]\n",
    "IdTrans=tmp.runcat.unique()\n",
    "if len(tmp)>0:\n",
    "    for a in IdTrans:\n",
    "        print websiteURL+str(a)\n",
    "else:\n",
    "    print \"No Variables\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
